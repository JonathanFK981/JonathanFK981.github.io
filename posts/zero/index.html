<!DOCTYPE html>
<html lang="zh-Hans"
  x-data
  :class="$store.darkMode.class()"
  :data-theme="$store.darkMode.theme()">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZeRO | dO.ob&#39;s Blog</title>

    

<link rel="canonical" href="http://localhost:1313/posts/zero/" />



<meta name="author" content="dOvob" />
<meta name="description" content="大型深度学习模型提供了显著的精度增益，但训练数十亿到数万亿的参数是具有挑战性的。现有的解决方案，例如数据和模型并行化，在获得计算、通信和开发效率的同时，在将这些模型装入有限的设备存储器方面表现出基本的局限性。我们开发了一种新的解决方案，ZeRO冗余优化器(Zero)，以优化内存，大大提高训练速度，同时增加可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保留了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按比例扩展模型大小。我们对内存需求和通信量的分析表明:使用今天的硬件，ZeRO有潜力扩展到超过1万亿个参数。（1000B参数）
我们实现并评估了ZeRO:它在400个GPU上以超线性加速训练了超过100B参数的大型模型，实现了15 Petaflops的吞吐量。就可用性而言，ZeRO可以训练高达13B参数的大型模型(例如，大于 Megatron GPT 8.3B和T5 11B)，而不需要模型并行性，这对于科学家来说更难应用。最后但并非最不重要的是，研究人员利用ZeRO的系统突破，创造了世界上最大的语言模型(17B参数)，具有破纪录的准确性。
" />


<meta name="keywords" content="Tag1,Tag2">



<meta name="generator" content="Hugo 0.146.2">


<meta property="og:url" content="http://localhost:1313/posts/zero/">
  <meta property="og:site_name" content="dO.ob&#39;s Blog">
  <meta property="og:title" content="ZeRO">
  <meta property="og:description" content="大型深度学习模型提供了显著的精度增益，但训练数十亿到数万亿的参数是具有挑战性的。现有的解决方案，例如数据和模型并行化，在获得计算、通信和开发效率的同时，在将这些模型装入有限的设备存储器方面表现出基本的局限性。我们开发了一种新的解决方案，ZeRO冗余优化器(Zero)，以优化内存，大大提高训练速度，同时增加可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保留了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按比例扩展模型大小。我们对内存需求和通信量的分析表明:使用今天的硬件，ZeRO有潜力扩展到超过1万亿个参数。（1000B参数）
我们实现并评估了ZeRO:它在400个GPU上以超线性加速训练了超过100B参数的大型模型，实现了15 Petaflops的吞吐量。就可用性而言，ZeRO可以训练高达13B参数的大型模型(例如，大于 Megatron GPT 8.3B和T5 11B)，而不需要模型并行性，这对于科学家来说更难应用。最后但并非最不重要的是，研究人员利用ZeRO的系统突破，创造了世界上最大的语言模型(17B参数)，具有破纪录的准确性。">
  <meta property="og:locale" content="zh_Hans">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-17T10:51:05+08:00">
    <meta property="article:modified_time" content="2025-04-17T10:51:05+08:00">
    <meta property="article:tag" content="Tag1">
    <meta property="article:tag" content="Tag2">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ZeRO">
  <meta name="twitter:description" content="大型深度学习模型提供了显著的精度增益，但训练数十亿到数万亿的参数是具有挑战性的。现有的解决方案，例如数据和模型并行化，在获得计算、通信和开发效率的同时，在将这些模型装入有限的设备存储器方面表现出基本的局限性。我们开发了一种新的解决方案，ZeRO冗余优化器(Zero)，以优化内存，大大提高训练速度，同时增加可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保留了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按比例扩展模型大小。我们对内存需求和通信量的分析表明:使用今天的硬件，ZeRO有潜力扩展到超过1万亿个参数。（1000B参数）
我们实现并评估了ZeRO:它在400个GPU上以超线性加速训练了超过100B参数的大型模型，实现了15 Petaflops的吞吐量。就可用性而言，ZeRO可以训练高达13B参数的大型模型(例如，大于 Megatron GPT 8.3B和T5 11B)，而不需要模型并行性，这对于科学家来说更难应用。最后但并非最不重要的是，研究人员利用ZeRO的系统突破，创造了世界上最大的语言模型(17B参数)，具有破纪录的准确性。">




<link rel="stylesheet" href="/css/output.css" />




<script>
  MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)']],
      displayMath: [['$$','$$']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 


    
<script>
  MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)'], ['$', '$']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 


    


<style>
  pre {
    padding: 1em;
    overflow: auto;
  }
</style>









    

    <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3/dist/cdn.min.js" integrity="sha256-PtHu0lJIiSHfZeNj1nFd6wTX+Squ255SGZ/fc8seCtM=" crossorigin="anonymous"></script>
  </head>

  <body x-data="{
    flip: false,
  }">
    
    <div id="dream-global-bg"></div>

    
<nav class="mt-4 lg:mt-8 py-4">

  
  <div class="container flex justify-between max-w-[65ch] mx-auto px-4 md:px-0">
  
    <section class="flex items-center gap-4">
      <div class="avatar cursor-pointer hover:avatar-online" @click="flip = !flip" title="翻转一下！">
        <div class="h-10 rounded-full">
          <img src="/img/logo.jpg" alt="Jonathan&#39;s Blog" />
        </div>
      </div>

      
      <div>
        
        <a href="http://localhost:1313/" class="text-lg font-semibold cursor-pointer">
          Jonathan&#39;s Blog
        </a>
        
        
      </div>
      
    </section>

    
    

    <div class="dropdown dropdown-end sm:hidden">
      <div tabindex="0" role="button" class="btn btn-ghost btn-square" aria-label="Select an option">
        <ion-icon name="menu" class="text-2xl"></ion-icon>
      </div>
      <ul tabindex="0" class="dropdown-content menu w-36 bg-base-100 rounded-box z-1 shadow-md">
        







<li>
  <div role="link" tabindex="0" class="inline-flex items-center p-2 cursor-pointer" @click="flip = !flip" title="关于">
    <ion-icon name="information-circle"></ion-icon>关于</div>
</li>





















<li>
  <a class="inline-flex items-center p-2 cursor-pointer" href="/posts" title="归档">
    <ion-icon name="archive"></ion-icon>
    归档
  </a>
</li>




<li>
  <a class="inline-flex items-center p-2 cursor-pointer" href="/categories" title="所有分类">
    <ion-icon name="grid"></ion-icon>
    所有分类
  </a>
</li>




<li>
  <a class="inline-flex items-center p-2 cursor-pointer" href="/tags" title="所有标签">
    <ion-icon name="pricetags"></ion-icon>
    所有标签
  </a>
</li>






      </ul>
    </div>
    <section class="hidden sm:flex sm:items-center sm:gap-2 md:gap-4">
      

      
      




<div role="link" tabindex="0" class="text-sm font-semibold cursor-pointer hover:underline" @click="flip = !flip" title="关于">关于</div>





      
      





      
      





      
      
<a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="/posts" title="归档">
  <ion-icon class="group-hover:text-primary-content" name="archive"></ion-icon>
</a>


      
      
<a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="/categories" title="所有分类">
  <ion-icon class="group-hover:text-primary-content" name="grid"></ion-icon>
</a>


      
      
<a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="/tags" title="所有标签">
  <ion-icon class="group-hover:text-primary-content" name="pricetags"></ion-icon>
</a>


      

      

      
    </section>
  </div>
</nav>


    <div class="flip-container" :class="{ 'flip-it': flip }">
      <div class="flipper">
        <div class="front">
          <div class="container">
            
<div class="lg:grid lg:grid-cols-4 gap-4 mt-4 px-4">
  <div class="hidden lg:block">
    
  </div>

  <div class="lg:col-span-2">
    <article class="mx-auto prose prose-quoteless dark:prose-invert" id="dream-single-post-main" itemscope itemtype="http://schema.org/Article">
      
  <meta itemprop="name" content="ZeRO">
  <meta itemprop="description" content="大型深度学习模型提供了显著的精度增益，但训练数十亿到数万亿的参数是具有挑战性的。现有的解决方案，例如数据和模型并行化，在获得计算、通信和开发效率的同时，在将这些模型装入有限的设备存储器方面表现出基本的局限性。我们开发了一种新的解决方案，ZeRO冗余优化器(Zero)，以优化内存，大大提高训练速度，同时增加可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保留了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按比例扩展模型大小。我们对内存需求和通信量的分析表明:使用今天的硬件，ZeRO有潜力扩展到超过1万亿个参数。（1000B参数）
我们实现并评估了ZeRO:它在400个GPU上以超线性加速训练了超过100B参数的大型模型，实现了15 Petaflops的吞吐量。就可用性而言，ZeRO可以训练高达13B参数的大型模型(例如，大于 Megatron GPT 8.3B和T5 11B)，而不需要模型并行性，这对于科学家来说更难应用。最后但并非最不重要的是，研究人员利用ZeRO的系统突破，创造了世界上最大的语言模型(17B参数)，具有破纪录的准确性。">
  <meta itemprop="datePublished" content="2025-04-17T10:51:05+08:00">
  <meta itemprop="dateModified" content="2025-04-17T10:51:05+08:00">
  <meta itemprop="wordCount" content="104">
  <meta itemprop="keywords" content="Tag1,Tag2">

      <header>
        <h1 itemprop="headline">ZeRO</h1>
        <p class="text-sm">
          
            星期四, 4月 17, 2025
          

          | <span>1分钟阅读</span>

          
          | <span>更新于
            
              星期四, 4月 17, 2025
            </span>
          
        </p>

        
        <div class="flex justify-between">
          
            <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    
      <span itemprop="name">dOvob</span>
    
  
  </span>
</div>

          

          <div class="flex items-center gap-2">
  
  

  
  
  
  
  
    <a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary"
      href="https://x.com/intent/post?text=ZeRO&amp;url=http://localhost:1313/posts/zero/" target="_blank" rel="noopener noreferrer"
      title="Share on X">
      <ion-icon class="group-hover:text-primary-content" name="logo-x"></ion-icon>
    </a>
  
    <a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary"
      href="https://facebook.com/sharer/sharer.php?u=http://localhost:1313/posts/zero/" target="_blank" rel="noopener noreferrer"
      title="Share on Facebook">
      <ion-icon class="group-hover:text-primary-content" name="logo-facebook"></ion-icon>
    </a>
  
    <a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary"
      href="https://wa.me/?text=ZeRO%20http://localhost:1313/posts/zero/" target="_blank" rel="noopener noreferrer"
      title="Share on WhatsApp">
      <ion-icon class="group-hover:text-primary-content" name="logo-whatsapp"></ion-icon>
    </a>
  

  
  
</div>

        </div>
      </header>

      <section id="dream-single-post-content" itemprop="articleBody">
        
          <img class="w-full z-30" src="/img/a.jpg" alt="ZeRO" />
        

        <p>大型深度学习模型提供了显著的精度增益，但训练数十亿到数万亿的参数是具有挑战性的。现有的解决方案，例如数据和模型并行化，在获得计算、通信和开发效率的同时，在将这些模型装入有限的设备存储器方面表现出基本的局限性。我们开发了一种新的解决方案，ZeRO冗余优化器(Zero)，以优化内存，大大提高训练速度，同时增加可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保留了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按比例扩展模型大小。我们对内存需求和通信量的分析表明:使用今天的硬件，ZeRO有潜力扩展到超过1万亿个参数。（1000B参数）</p>
<p>我们实现并评估了ZeRO:它在400个GPU上以超线性加速训练了超过100B参数的大型模型，实现了15 Petaflops的吞吐量。就可用性而言，ZeRO可以训练高达13B参数的大型模型(例如，大于 Megatron GPT 8.3B和T5 11B)，而不需要模型并行性，这对于科学家来说更难应用。最后但并非最不重要的是，研究人员利用ZeRO的系统突破，创造了世界上最大的语言模型(17B参数)，具有破纪录的准确性。</p>
<h1 id="extended-introduction">Extended Introduction</h1>
<p>深度学习(DL)模型变得越来越大，模型大小的增加提供了显著的准确性增益。在自然语言处理(NLP)领域，变形金刚已经为大型模型铺平了道路，如Bert-large (0.3B) [1]，GPT-2 (1.5B) [2)，Megatron-LM (8.3B) [3]，T5 (11B) [4]。为了实现模型规模从数十亿到数万亿参数的持续增长，我们经历了训练它们的挑战——它们显然不适合单个设备(如GPU或TPU)的内存，简单地添加更多设备将无助于扩大训练规模。</p>
<p>基本数据并行性(DP)不会减少每台设备的内存，并且在当前一代32 GB内存的GPU上，对于参数超过1.4B的型号，内存不足。其他现有的解决方案，例如流水线并行(PP)、模型并行(MP)，CPU卸载等在功能性、可用性以及内存和计算/通信效率之间进行权衡，但所有这些对于速度和规模训练都至关重要。</p>
<p>在现有的用于训练大型模型的不同解决方案中，MP可能是最有前途的。当前文献中最大的模型，11B T5模型[4]和Megatron-LM 8.3B [3]，都是由模型并行性驱动的，分别在Mesh-Tensorflow [5]和Megatron-LM[3]中实现。但是，MP不能扩展到超过这些型号的尺寸。MP垂直分割模型，将每层中的计算和参数划分到多个设备上，需要每层之间进行大量通信。因此，它们在GPU间通信带宽较高的单个节点内工作良好，但在单个节点之外效率会迅速下降[3]。我们在两个DGX-2节点上使用Megatron-LM测试了一个40B参数模型，并观察到每个V100 GPU大约有5 T flops(不到硬件峰值的5%)。</p>
<p>那么，如何才能克服现有解决方案的局限性，更高效地训练大型模型呢？为了回答这个问题，我们首先分析现有系统在模型训练上的全部内存消耗，并将其分为两个部分:1)对于大型模型，大部分内存被模型状态占用，模型状态包括优化器状态(例如Adam [6]中的动量和方差)、梯度和参数。2)剩余内存被激活、临时缓冲区和不可用的碎片内存消耗，我们统称为剩余状态。我们开发ZeRO|ZeRO冗余优化器|以优化两者的内存效率，同时获得高计算和通信效率。由于这两部分面临不同的挑战，我们相应地开发和讨论了它们的解决方案。</p>
<p><strong>优化模型状态存储器</strong>
模型状态通常在训练期间消耗最大量的存储器，但是诸如DP和MP之类的现有方法没有提供令人满意的解决方案。DP具有良好的计算/通信效率，但是具有较差的存储效率，而MP可能具有较差的计算/通信效率。更具体地说，DP跨所有数据并行过程复制整个模型状态，导致冗余的存储器消耗；虽然MP划分这些状态以获得高存储效率，但是经常导致太细粒度的计算和昂贵的通信，这降低了缩放效率。此外，所有这些方法静态地维护整个训练过程中所需的所有模型状态，即使在训练期间并非所有时间都需要所有模型状态。基于这些观察，我们开发了ZeRODP、ZeRO功耗的数据并行性，它实现了DP的计算/通信效率，同时实现了MP的存储效率。ZeRO-DP通过划分模型状态而不是复制模型状态来消除数据并行过程中的内存状态冗余，并通过在训练期间使用动态通信调度来保留DP的计算粒度和通信量，从而保持计算/通信效率。</p>
<p>ZeRO-DP有三个主要的优化阶段(如图1所示)，对应于优化器状态、梯度和参数的划分。累计启用时:
1)优化器状态分区(Pos):内存减少4倍，通信量与DP相同；
2)增加梯度划分(Pos+g):8倍内存缩减，通信量与DP相同；
3)增加参数划分(Pos+g+p):内存减少与DP度数Nd成线性关系。</p>
<p>例如，跨64个GPU(Nd = 64)进行拆分将会减少64倍的内存。通信量有50%的适度增长。</p>
<p>ZeRO-DP消除了内存冗余，并使群集的全部聚合内存容量可用。在所有三个阶段都启用的情况下，ZeRO可以在1024个NVIDIA GPUs上训练一个万亿参数的模型。一个万亿参数的模型，有一个像Adam [6]那样的优化器&mdash;-16位精度需要大约16tb的内存来保存优化器状态、梯度和参数。16TB除以1024等于16GB，这在GPU的合理范围内(例如，32GB的设备内置内存)。</p>
<p>ZeRO-DP消除了内存冗余，并使群集的完整汇总内存容量可用。启用了所有三个阶段，ZeRO只能在1024 NVIDIA GPU上训练万亿参数模型。具有16位精确度的优化器（如Adam [6]）的优化器的一个万亿参数模型需要大约16TB的存储器，以保持优化器状态，​​梯度和参数。 16TB除以1024为16GB，它符合GPU的合理限制（例如，具有32GB的设备内存）。</p>
<p>优化ZeRO-DP后的剩余状态内存可提高模型状态的内存效率，激活、临时缓冲区和不可用内存碎片所消耗的剩余内存可能会成为二级内存瓶颈。我们开发ZeRO-R来分别优化这三个因素消耗的剩余内存。</p>
<p>1)对于激活(从向前传递存储，以便执行向后传递)，我们注意到检查点[7]有所帮助，但对于大型模型是不够的。因此，ZeRO-R通过激活分区识别和移除现有MP方法中的激活复制来优化激活存储器。它还会在适当的时候将激活任务卸载给CPU。</p>
<ol start="2">
<li>ZeRO-R定义了临时缓冲区的适当大小，以达到存储器和计算效率的平衡。</li>
</ol>
<p>3)由于不同张量寿命的变化，我们在训练期间观察到碎片记忆。即使有足够的可用内存，由于碎片造成的连续内存不足也会导致内存分配失败。ZeRO-R根据张量的不同寿命主动管理内存，防止内存碎片。</p>
<p>ZeRO-DP和ZeRO-R结合在一起形成了一个强大的DL训练内存优化系统，我们统称为ZeRO</p>
<p><strong>ZeRO和MP</strong>：由于ZeRO消除了DP的内存效率低下，因此很自然地问：我们仍然需要MP吗？ZeRO如何与MP一起使用？对于ZeRO，MP将成为仅适合大型模型的目的而成为吸引力的选择。ZeRO-DP至少在减少每位设备记忆的足迹上与MP一样有效，或者当MP无法均匀分配模型时，有时更有效。它还具有可比或更好的缩放效率。此外，数据并行性非常易于使用，以至于它在不同的工作负载中广泛适用，而ZeRO和MP：由于ZeRO消除了DP的内存效率低下，因此自然而然地问：我们仍然需要MP吗？ZeRO如何与MP一起使用？对于ZeRO，MP将成为仅适合大型模型的目的而成为吸引力的选择。ZeRO-DP至少在减少每位设备记忆的足迹上与MP一样有效，或者当MP无法均匀分配模型时，有时更有效。它还具有可比或更好的缩放效率。此外，数据并行性非常易于使用，以至于它在不同的工作负载中广泛适用，而今天的MP方法通常需要模型开发人员做一些工作来修改他们的模型，系统开发人员做一些工作来制定分布式操作符，而现有的工作如Megatron-LM只支持有限的一组操作符和模型。</p>
<p>也就是说，仍然有我们想要利用MP的情况:
I)当与ZeRO-R一起使用时，MP可以减少非常大的模型的激活内存占用。
ii)对于激活内存不是问题的较小模型，当单独使用DP的合计批量太大而无法实现良好的收敛性时，MP也有好处。1在这种情况下，可以将ZeRO和MP结合起来，以使模型符合可接受的合计批量。</p>
<p>我们发现，ZeRO可以与MP结合使用，在DP等级为Nd、MP等级为Nm的每个器件上，最大理论内存减少量为Nd ×Nm倍。这可以让我们在1024个GPU上安装万亿参数模型，具有16路模型并行性(在每个DGX2节点内)和跨节点的64路数据并行性，并使用适度的批处理大小高效地运行它！</p>
<p><strong>Implementation &amp; Evaluation</strong>
ZeRO中完整的优化集可以让我们在当今的高端硬件集群上运行具有万亿参数的模型(例如，具有1K V100 GPUs)，但是，硬件计算能力仍然太有限，并且训练时间可能太长(&gt; 1年)。因此，我们此次实施的重点是高效地支持比最先进(SOTA)多10倍参数(100B参数)的模型，同时仍在当前硬件的计算能力范围内。我们在ZeRO中实现并评估了一个优化子集，称为ZeRO-100 b | Pos+g of ZeRO-DP plus ZeRO-R |,它允许我们实现这个目标。结果显示:</p>
<p>Model Size:结合MP，ZeRO-100B高效运行170B参数模型，而像单独使用威震天这样的现有系统无法高效扩展到40B参数以上，如图2所示。与SOTA相比，模型尺寸增加了8倍以上。</p>
<p>speed:提高记忆效率可以提高较高的吞吐量和更快的训练。如图2所示，ZeRO在400个NVIDIA V100 GPU群集上运行100B参数模型，每个GPU超过38个TFLOPS，并且在15个PETAFLOPS上进行了汇总性能。与SOTA相比，相同型号的训练速度的提高超过10倍。</p>
<p>Scalability：我们在64-400个GPU的范围内观察到超线性加速，当我们将GPU的数量增加一倍时，性能会增加一倍以上。这是ZeRO-DP的一个特性，当我们提高DP等级时，它可以减少模型状态的内存占用，从而使我们能够适应每个GPU的更大批量，从而获得更好的性能。随着我们将GPU的数量增加到400个以上，我们预计这种行为将会继续下去。</p>
<p>Democratization of Large Model Training：ZeRO-100B使数据科学家能够训练具有多达13B个参数的模型，而不需要任何需要模型重构的MP或PP，其中13B是比文献中最大模型更多的参数(具有11B个参数的T5)。因此，数据科学家可以自由地对大型模型进行实验，而不必担心并行性。相比之下，现有系统(例如PyTorch分布式数据并行)在1.4B参数模型下会耗尽内存。</p>
<p>New SOTA Model：ZeRO powers拥有17B参数和破纪录精度的最大语言模型图灵-NLG [9]。</p>
<p>我们分享ZeRO作为我们的开源DL训练优化库DeepSpeed2的一部分。我们计划在2020年5月底之前发布本文中描述的所有实现，并通过启用零DP阶段3分区参数(Pos+g+p)进一步扩展它以支持1万亿个参数。我们计划让ZeRO对DL社区完全开放，以促进大规模模型训练的发展和民主化。</p>
<h1 id="related-work">Related Work</h1>
<h2 id="data-model-and-pipeline-parallelism">Data, Model and Pipeline Parallelism</h2>
<p>并行化是大规模训练大型模型的关键策略。对于适合设备内存用于训练的模型，数据并行性(DP)用于将训练扩展到多个设备。在DP中，模型参数在每个设备上复制。在每一步，小批量被均匀地划分在所有数据并行过程中，使得每个过程对数据样本的不同子集执行前向和后向传播，并使用过程间的平均梯度来局部更新模型。</p>
<p>当模型不适合设备内存时，模型并行性(MP) [5，3]和流水线并行性(PP) [10，11]分别以垂直和水平方式在进程间分割模型。第一节讨论了零点与DP和MP的关系。我们现在讨论PP以及它与减少内存消耗的关系。</p>
<p>PP在不同的设备上跨层水平分割模型，并使用微批处理来隐藏管道气泡[10，11]。由于水平分割和微批处理，模型功能(如捆绑权重和批处理标准化)很难实现。流行的PP实现，如G-pipe [10]对模型参数和总激活进行分区，但需要与管道分区数量成比例的批量大小来隐藏管道气泡。大批量会影响收敛速度，同时还需要大量内存来存储激活。PipeDream [12]中PP的另一种实现保留了旧参数的多个副本，以隐藏管道气泡，而不会显著增加批处理大小，从而降低内存效率。此外，该实现不等同于标准的DL训练，并且对训练收敛有影响。相比之下，ZeRO获得了与PP相同或更好的存储效率，而没有招致PP的功能、性能和收敛相关的限制</p>

        
      </section>

      

      
    </article>
  </div>

  <div
    x-data="tocHighlighter()"
    @scroll.window="debouncedScroll"
    class="hidden lg:flex lg:flex-col lg:items-end">
    
      <nav id="TableOfContents">
  <ol>
    <li><a href="#data-model-and-pipeline-parallelism">Data, Model and Pipeline Parallelism</a></li>
  </ol>
</nav>
    
  </div>
</div>


            
<footer class="flex justify-between items-center gap-2 max-w-[65ch] mx-auto px-4 md:px-0 py-12">

  <div>
  
  <p>
    © 2025 dO.ob&#39;s Blog
  </p>
  

  
  <p class="text-sm">
    🌱
    <span class="text-base-content/60">
      Powered by <a class="hover:underline" href="https://gohugo.io/" target="_blank">Hugo</a> with theme
      <a class="hover:underline" href="https://github.com/g1eny0ung/hugo-theme-dream" target="_blank">Dream</a>.</span
    >
  </p>
  
</div>

  <div
  x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }"
  class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"
>
  <template x-for="icon in icons">
    <div
      role="button"
      tabindex="0"
      :aria-label="'Select ' + icon.name + ' mode'"
      class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary"
      :class="$store.darkMode.icon() === icon.name && 'bg-primary'"
      @click="$store.darkMode.toggle(icon.status)"
    >
      <ion-icon
        :name="`${icon.name}-outline`"
        class="group-hover:text-primary-content"
        :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"
      >
      </ion-icon>
    </div>
  </template>
</div>

</footer>

          </div>
        </div>
        <div class="back">
          <div class="container">
            
            <div class="max-w-[65ch] mt-8 mx-auto px-4">
  
  
  
  <div>
    <div class="mb-4 text-lg font-medium">关于我</div>

    <div class="prose dark:prose-invert">
      <p>我是一名AI从业者，致力于人工智能和数据驱动行业。</p>
<p>踏上取经路，比抵达灵山更重要</p>

    </div>
  </div>
  <div class="divider divider-vertical"></div>
  
  

  

  
</div>

            

            
<footer class="flex justify-between items-center gap-2 max-w-[65ch] mx-auto px-4 md:px-0 py-12">

  <div>
  
  <p>
    © 2025 dO.ob&#39;s Blog
  </p>
  

  
  <p class="text-sm">
    🌱
    <span class="text-base-content/60">
      Powered by <a class="hover:underline" href="https://gohugo.io/" target="_blank">Hugo</a> with theme
      <a class="hover:underline" href="https://github.com/g1eny0ung/hugo-theme-dream" target="_blank">Dream</a>.</span
    >
  </p>
  
</div>

  <div
  x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }"
  class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"
>
  <template x-for="icon in icons">
    <div
      role="button"
      tabindex="0"
      :aria-label="'Select ' + icon.name + ' mode'"
      class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary"
      :class="$store.darkMode.icon() === icon.name && 'bg-primary'"
      @click="$store.darkMode.toggle(icon.status)"
    >
      <ion-icon
        :name="`${icon.name}-outline`"
        class="group-hover:text-primary-content"
        :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"
      >
      </ion-icon>
    </div>
  </template>
</div>

</footer>

          </div>
        </div>
      </div>
    </div>

    <script>
  window.lightTheme = "emerald"
  window.darkTheme = "forest"
</script>





<script src="/js/main.js"></script>

    







<script src="/js/toc.js"></script>





    

    

    

    

    <script type="module" src="https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.esm.js" integrity="sha256-/IFmi82bIhdYWctu0UddSlJqpnzWm7Vh2C4CM32wF/k=" crossorigin="anonymous"></script>
    <script nomodule src="https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.js" integrity="sha256-mr7eJMX3VC3F7G32mk4oWp1C6a2tlMYxUdptfT7uKI8=" crossorigin="anonymous"></script>
  </body>
</html>
